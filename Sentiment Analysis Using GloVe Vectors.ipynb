{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IsraelAdekanye/ML_Jupyter/blob/main/Sentiment%20Analysis%20Using%20GloVe%20Vectors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68beb7cf-fdf0-4c5d-b729-dd5424454778",
      "metadata": {
        "id": "68beb7cf-fdf0-4c5d-b729-dd5424454778",
        "outputId": "6b9a8f1e-4315-4821-a271-e251aa26127c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/israel/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package twitter_samples to\n",
            "[nltk_data]     /Users/israel/nltk_data...\n",
            "[nltk_data]   Package twitter_samples is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /Users/israel/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import twitter_samples\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "import re\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('twitter_samples')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "\n",
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cad37dca-8d09-4c3b-9cab-84e2da506da1",
      "metadata": {
        "id": "cad37dca-8d09-4c3b-9cab-84e2da506da1"
      },
      "outputs": [],
      "source": [
        "# select the set of positive and negative tweets\n",
        "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "all_negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
        "\n",
        "tweets = all_positive_tweets + all_negative_tweets\n",
        "labels = np.append(np.ones((len(all_positive_tweets), 1)), np.zeros((len(all_negative_tweets), 1)), axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fea24d7d-b2a8-4160-bf03-04f0309b8fbf",
      "metadata": {
        "id": "fea24d7d-b2a8-4160-bf03-04f0309b8fbf"
      },
      "outputs": [],
      "source": [
        "stemmer = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Get list of stopwords (e.g., \"the\", \"is\", \"and\", etc.)\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Preprocessing function to clean and normalize the text\n",
        "def preprocess(text):\n",
        "    text = text.lower()  # Lowercase text\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    tokens = text.split()  # Tokenize by spaces\n",
        "    # Remove stopwords and apply stemming\n",
        "    # filtered = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
        "    filtered = [stemmer.stem(word) for word in tokens if word not in stop_words]\n",
        "    return \" \".join(filtered)  # Return preprocessed sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ea7a579-debc-4c86-aaee-6474da07e09f",
      "metadata": {
        "id": "4ea7a579-debc-4c86-aaee-6474da07e09f"
      },
      "outputs": [],
      "source": [
        "def load_glove_embeddings(file_path):\n",
        "    embeddings = {}\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            vector = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings[word] = vector\n",
        "    return embeddings\n",
        "\n",
        "glove_path = \"../glove.6B/glove.6B.200d.txt\"\n",
        "glove_embeddings = load_glove_embeddings(glove_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bf7a7bf-3829-4eba-9493-6470df87bdf7",
      "metadata": {
        "id": "4bf7a7bf-3829-4eba-9493-6470df87bdf7"
      },
      "outputs": [],
      "source": [
        "def vectorize_tweets(tweets, dim=200):\n",
        "    vectors = [glove_embeddings[tweet] for tweet in tweets.split() if tweet in glove_embeddings]\n",
        "    if vectors:\n",
        "        return np.mean(vectors, axis=0)\n",
        "    else:\n",
        "        return np.zeros(dim)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec6295d9-d854-4038-bf14-50a166937f7f",
      "metadata": {
        "id": "ec6295d9-d854-4038-bf14-50a166937f7f"
      },
      "outputs": [],
      "source": [
        "tweets = [preprocess(x) for x in tweets]\n",
        "tweets_X = [vectorize_tweets(tweet) for tweet in tweets]\n",
        "tweets_Y = pd.Series(np.squeeze(labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64f46ad6-c0ef-48c0-ba2c-7ecd4fa231cd",
      "metadata": {
        "id": "64f46ad6-c0ef-48c0-ba2c-7ecd4fa231cd"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    tweets_X, tweets_Y, test_size=0.2, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b2053d2-d7f8-4010-8a2f-0363c72006cf",
      "metadata": {
        "id": "3b2053d2-d7f8-4010-8a2f-0363c72006cf",
        "outputId": "c878f4fd-5ded-4488-84ca-d4f06d508f05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.687\n",
            "0.7010416666666667\n",
            "0.6650197628458498\n",
            "0.6825557809330629\n"
          ]
        }
      ],
      "source": [
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "Accuracy = accuracy_score(y_test, y_pred)\n",
        "Precision = precision_score(y_test, y_pred)\n",
        "Recall = recall_score(y_test, y_pred)\n",
        "F1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(Accuracy)\n",
        "print(Precision)\n",
        "print(Recall)\n",
        "print(F1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29835dce-3238-4795-8cfa-46581ed2aabd",
      "metadata": {
        "id": "29835dce-3238-4795-8cfa-46581ed2aabd",
        "outputId": "36543870-3e6a-4aaf-bb20-2824b316c91a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.]\n"
          ]
        }
      ],
      "source": [
        "# raw_tweet =  'I detest your compaany'\n",
        "# processed_tweet = preprocess(raw_tweet)\n",
        "# # print(processed_tweet)\n",
        "# vectorized_tweet = vectorize_tweets(processed_tweet)\n",
        "# print(model.predict([vectorized_tweet]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8219d953-3ef7-407d-b9d8-a3bdb602e8fa",
      "metadata": {
        "id": "8219d953-3ef7-407d-b9d8-a3bdb602e8fa",
        "outputId": "4ab12b46-f625-4f12-9a91-f4bf25c0ce96"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\u001b[31m2025/05/13 06:17:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üèÉ View run Logistic Regression with GloVe Embeddings with Stemmmer 200d at: http://127.0.0.1:5000/#/experiments/447362716636180076/runs/6ef1ed65632d46448683e9cfdc881741\n",
            "üß™ View experiment at: http://127.0.0.1:5000/#/experiments/447362716636180076\n"
          ]
        }
      ],
      "source": [
        "mlflow.set_experiment(\"First Experiment with Sentiment Analysis using Logistic Regression\")\n",
        "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
        "\n",
        "with mlflow.start_run(run_name=\"Logistic Regression with GloVe Embeddings with Stemmmer 200d\"):\n",
        "\n",
        "    # Log evaluation metrics\n",
        "    mlflow.log_metric(\"Accuracy\", Accuracy)\n",
        "    mlflow.log_metric(\"Precision\", Precision)\n",
        "    mlflow.log_metric(\"Recall\", Recall)\n",
        "    mlflow.log_metric(\"F1_score\", F1)\n",
        "\n",
        "    # Log model hyperparameters\n",
        "    mlflow.log_param(\"solver\", model.solver)\n",
        "    mlflow.log_param(\"C\", model.C)\n",
        "    mlflow.log_param(\"max_iter\", model.max_iter)\n",
        "\n",
        "    # Log embedding-specific info\n",
        "    mlflow.log_param(\"embedding\", \"GloVe\")\n",
        "    mlflow.log_param(\"embedding_dim\", 100)\n",
        "    mlflow.log_param(\"vectorizer\", \"mean_pooling_glove\")\n",
        "\n",
        "    # Log the model\n",
        "    mlflow.sklearn.log_model(model, \"LogisticRegressionSentimentModel\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4424b747-b718-48d0-ade0-e99a7085bf61",
      "metadata": {
        "id": "4424b747-b718-48d0-ade0-e99a7085bf61"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Native ML ENV",
      "language": "python",
      "name": "machine_learning_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}